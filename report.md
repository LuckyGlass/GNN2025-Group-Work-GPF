## 1 介绍

Prompt tuning 原是应用于大语言模型的方法。现有大模型具有强大的指令遵循能力，能够根据输入的文字理解任务，因此用户可以用输入文字定制大模型的功能，该段引导大模型理解问题、解决任务的提示性文本称为 Prompt。随着大模型发展，一类方法探索非自然语言、非人工设计的“Prompt”，统称为 Soft prompt。具体而言，大模型将自然语言转换为 Embedding 后进行相关运算，因此这一类方法探索直接将一个连续向量序列作为 Prompt embedding 输入模型，称为 Soft prompt，进而用多种学习方法自动优化 Soft prompt。

此外，Prompt tuning 由于可修改参数量低，不直接修改模型权重，一定程度上避免了过拟合风险。

Prompt tuning 本质上是通过修改输入，而非修改模型权重，提升下游任务能力。在图领域，同样可以修改输入的图。例如，一类启发式的方法是计算每个节点的多跳闭包，加边连接闭包中心和闭包的其他节点，从而缩短图中各节点的距离。然而启发式的方法不一定适用于任意下游任务，GPF (Fang et al.) 和 EdgePrompt (Fu et al.) 探索了一类根据下游任务自动优化图输入的方法。本实验深入研究了两种方法，复现了论文内容，并提出改进方案，通过大量实验证明了改进的有效性。

## 2 论文方法概述

## 2.1 Universal Prompt Tuning for Graph Neural Networks

该论文提出了 GPF 方法。虽然对图输入的修改涉及对点特征的修改和对图结构的修改，但对图结构的修改涉及对任意两点间的连边的预测，复杂度不可接受，GPF 仅考虑修改点特征。具体而言，针对给定下游任务，GPF 学习一个和输入特征等维度的特征增量 $p$，设输入的节点特征为 $(x_1,\dots,x_N)$（$N$ 为节点总数）。GPF 更新节点特征为 $(x_1+p,\dots,x_N+p)$，其余不改变，将更新的输入传入预训练的模型（连接下游任务的输出头）得到模型预测。

$p$ 与下游任务输出头同时在下游任务的训练集上优化。

除此之外，该论文提出了方法 GPF-Plus 作为改进。单个特征增量 $p$ 容量非常局限，GPF-Plus 学习 $K$ 个特征增量 $p_1,\dots,p_K$ 以及与之相关的索引 $k_1,\dots,k_K$，更新的点特征为
$$
x'_i=\frac{\sum_{j=1}^{K}\exp\{k_j^Tx_i\}p_j}{\sum_{j=1}^K\exp\{k_j^Tx_i\}}.
$$

该论文证明了在特征容量足够的前提下，任意对图输入的修改（包括对图结构的修改）等价于一种仅对节点特征的修改，从而保证了“仅修改点特征”这一简化不会损伤 Prompt tuning 的表达能力。本质上，修改模型结构是修改了图网络中消息传递的路径，影响节点的隐层特征，而修改输入特征可以达到相同的效果。

## 3 方法改进

直观的，增加可微调的参数量能够进一步提升 Prompt tuning 的表达能力。GPF-Plus 提出优化多个特征增量，然而它仍然局限于对输入的修改。由于模型的权重不变、图结构不变，修改输入对输出的影响局限且不直观，我们提出在图网络的输入层以及所有隐层上添加特征增量。

设图网络的层数为 $L$，第 $l$ 层的输出记为 $h^{(l)}_{i}$，简便起见，记输入 $h_i^{(0)}:=x_i$；第 $l$ 层接受 $l-1$ 层的所有节点特征以及图结构，输出第 $l$ 层的节点特征，记为 $(h_{1}^{(l)},\dots,h_{N}^{(l)})=F_{l}(h_{1}^{(l-1)},\dots,h_{N}^{(l-1)};G)$。我们修改 $F_l$ 的输入：
$$
(h_1^{(l)},\dots,h_N^{(l)})=F_{l}(h_{1}^{(l)}+p^{(l)},\dots,h_{N}^{(l)}+p^{(l)};G)
$$
其中 $p^{(l)}$ 是与 $h_{i}^{(l)}$ 等维度的隐层特征增量。

## 4 实验

我们复现了 GPF 在生物领域的部分下游任务上的结果，并在相同的任务上与我们改进的方法做对比。GPF 在多种预训练模型上进行实验，保证方法的泛用性；我们选取了其中的两种，Infomax 和 AttrMasking，使用相同的预训练模型权重，与 GPF 进行对比。

在每组实验（一种预训练方法和一个下游任务）中，我们采用了 5 个不同的随机数种子进行重复实验，保证实验结论的可靠性。下表汇报了每组实验在 5 个随机数种子下的指标的平均值，不同随机数种子的实验结果详见附录。

| Pretrain | Algorithm | BBBP | Tox21 | ToxCast | SIDER | ClinTox | BACE |
|:---|:---|:---:|:---:|:---:|:---:|:---:|:---:|
|Infomax|GPF (Original)|<u>66.83</u>|**79.09**|**66.10**|**66.17**|<u>73.56</u>|**83.60**|
||GPF (Reproduced)|65.51|77.58|65.23|<u>65.57</u>|73.32|82.16|
||GPF-Multi|**67.76**|<u>78.19</u>|<u>65.97</u>|64.98|**76.58**|<u>83.35</u>|
|AttrMasking|GPF (Original)|**68.09**|<u>79.04</u>|<u>66.32</u>|**69.13**|75.06|**84.33**|
||GPF (Reproduced)|<u>67.29</u>|78.57|65.77|68.35|<u>75.31</u>|83.82|
||GPF-Multi|67.11|**79.44**|**66.46**|<u>68.46</u>|**75.67**|<u>83.84</u>|

改进的方法在绝大多数实验中表现优于 GPF 的复现结果。我们按照 GPF 作者开源的代码复现了结果，然而多数任务上没有达到论文上汇报的结果。考虑硬件条件、具体实验设置的匹配性，我们认为将改进的方法与复现的结果作对比更合理，因此我们认为本实验提出的改进方法能够带来稳定提升。

上述所有实验在单张 4090 上完成，所有实验总时长约 75 GPU小时。

## 附录

### A. 在不同随机数种子下 GPF 的复现指标和改进算法的指标

|Pretrain|  Method	|Seed	|BBBP	|Tox21	|ToxCast	|SIDER	|ClinTox	|BACE|
|:---|:---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|Infomax	|GPF (Original)	|	|66.83 	|79.09 	|66.10 	|66.17 	|73.56 	|83.60 |
|	|GPF (Reproduced)	|42	|64.37 	|77.06 	|65.32 	|66.75 	|75.08 	|82.02| 
|	|	|77	|67.22 	|78.16 	|65.02 	|65.06 	|68.89 	|81.85| 
|	|	|728	|64.22 	|77.69 	|65.09 	|64.93 	|74.17 	|82.98| 
|	|	|2025	|65.55 	|77.73 	|65.48 	|65.36 	|73.63 	|82.00| 
|	|	|1234	|66.17 	|77.24 	|65.23 	|65.77 	|74.82 	|81.95| 
|	|	|avg	|65.51 	|77.58 	|65.23 	|65.57 	|73.32 	|82.16| 
|	|	|std	|1.26 	|0.43 	|0.18 	|0.73 	|2.54 	|0.46| 
|	|GPF-Multi	|42	|67.64 	|78.11 	|66.20 	|64.61 	|78.39 	|83.60| 
|	|	|77	|67.63 	|77.98 	|65.92 	|65.16 	|79.82 	|83.05| 
|	|	|728	|69.16 	|78.02 	|65.54 	|65.71 	|75.07 	|83.93| 
|	|	|2025	|66.66 	|78.24 	|66.09 	|64.96 	|76.36 	|83.29| 
|	|	|1234	|67.69 	|78.58 	|66.13 	|64.44 	|73.27 	|82.89| 
|	|	|avg	|67.76 	|78.19 	|65.97 	|64.98 	|76.58 	|83.35| 
|	|	|std	|0.90 	|0.24 	|0.26 	|0.50 	|2.60 	|0.42| 
|AttrMasking|	GPF (Original)|	|68.09 	|79.04 	|66.32 	|69.13 	|75.06 	|84.33| 
|	|GPF (Reproduced)	|42	|67.93 	|78.26 	|66.10 	|67.79 	|65.69 	|83.34| 
|	|	|77	|65.58 	|78.43 	|66.45 	|69.26 	|74.60 	|84.44| 
|	|	|728	|68.02 	|78.55 	|65.53 	|69.68 	|79.70 	|83.38| 
|	|	|2025	|66.10 	|78.40 	|65.39 	|67.70 	|77.83 	|83.05| 
|	|	|1234	|68.81 	|79.23 	|65.38 	|67.32 	|78.72 	|84.89| 
|	|	|avg	|67.29 	|78.57 	|65.77 	|68.35 	|75.31 	|83.82| 
|	|	|std	|1.38 	|0.38 	|0.48 	|1.05 	|5.71 	|0.80| 
|	|GPF-Multi	|42	|67.58 	|79.64 	|66.85 	|69.53 	|76.78 	|84.14| 
|	|	|77	|65.44 	|79.34 	|66.36 	|68.92 	|74.86 	|84.61| 
|	|	|728	|66.96 	|79.58 	|66.21 	|67.71 	|76.49 	|83.64| 
|	|	|2025	|68.03 	|79.31 	|66.34 	|67.86 	|74.71 	|82.75| 
|	|	|1234	|67.55 	|79.33 	|66.55 	|68.26 	|75.53 	|84.07| 
|	|	|avg	|67.11 	|79.44 	|66.46 	|68.46 	|75.67 	|83.84| 
|	|	|std	|1.01 	|0.15 	|0.25 	|0.76 	|0.93 	|0.70| 
